* From "What is reading" draft:
#+begin_src markdown
What does this model of *reading* code tell us about *writing* code?

When we're skimming code, we're scanning for key information; we don't want to parse anything visually dense. Even when we're reading code at a higher level, we rarely want to mentally inspect every little detail. Only when we get to close reading—once we're already investing time and attention to a specific part of the codebase—do we need to follow everything. For the first two modes, we care about what we can understand **at a glance**. How well can we navigate and understand code without visually parsing and interpreting each line in detail?

As an illustrative—if somewhat extreme—example, let's compare three versions of the same logic. Here's some Java code using [BigDecimal]:

``` java
final BigDecimal result = a.multiply(x.pow(2)).plus(b.multiply(x.plus(c)));
```

Java does not have operator overloading. If it did[^java-operator-overloading], the code might look like this instead:

``` java
final BigDecimal result = a * (x * x) + b * x + c;
```

Both of these implement the same mathematical formula:

$$
\text{result} = ax^2 + bx + c
$$

This is about as simple as a polynomial gets, but even that wasn't immediately clear from the first version of the code: you'd have to pay attention to read the sequence of named method calls to understand what was going on. The version with overloaded operators is a real contrast, although it still requires more attention than the math notation. If the first snippet is like reading a paragraph, the second snippet is like reading a short sentence and the math notation is like reading a single word.

With the math notation, we can *instantly* tell we're looking at a polynomial just from the shape. The information we care about for polynomials are the terms; the addition and multiplication holding everything together is more like an implementation detail. The math notation reflects this by visually grouping together the information for each term and using an operator (+) as "punctuation" to pull it together. Addition is part of what makes the polynomial *a polynomial* but, once we know what we're looking at, it can fade into the background.

Math notation in general tends to convey information effectively at a glance, which makes it great for skimming and higher-level reading, but can be a bit of a pain for understanding all the details. When I first see a math book, I'll have to spend some extra effort deciphering notation in my head—but, once I'm used to it, I can quickly skip around mathematical texts by just looking at equations until I find what I'm looking for.

[BigDecimal]: https://docs.oracle.com/javase/8/docs/api/java/math/BigDecimal.html

[^java-operator-overloading]: Example from [Is it time for operator overloading in Java?](https://blogs.oracle.com/javamagazine/post/is-it-time-for-operator-overloading-in-java) in
Java Magazine

</div>
<div class="content">

Humans are naturally good at tracking context. The same word or symbol [can have different meanings in different contexts][polysemy] and people *don't even notice*. Have you ever thought about how the "white" in "white wine" is really yellow? Or how the parentheses in `f(x)` mean "function application", but the parentheses in `(a + b) * c` are just for grouping? This is a classic obstacle for language learners—in part because native speakers find resolving the ambiguity *so easy* that they don't realize it would need explanation!

This applies to code as well. **How people will understand code depends on the context that they have.** And readers will have different amounts of context depending on the mode they're in:

  1. When somebody is *skimming* code, they're quickly covering broader sections of the code so they'll have less context.

  2. When somebody is *reading* code, they're focused on a something specific, so they have pretty solid context.

  3. By the time somebody gets to a *close reading* of the code, they'll have the clearest idea of where they are in the code and what's going on.

This dynamic affects how I write and organize code. Parts of the code that are relevant to closer reading—like helper functions and variables—are written with more specific context in mind. Inside the guts of a function, short names like `x` or `t` can be perfectly clear and help keep expressions easy to visually parse; but I would reach for a more explicit name for the parts of the code relevant for skimming.

[polysemy]: https://en.wikipedia.org/wiki/Polysemy
#+end_src

* General Ideas
  - code that is conceptually related should *look related*
    - even if implementation isn't!
  - code that is *not* conceptually related should *look different*
    - even if implementation is similar!
  - think about the *shape* of your code
    - verbose/unnecessary names, boilerplate *obscure* the shape of code
* Example: Math Notation
  - highlight *structure* of an expression
    - think about polynomials: like a set of terms
    - operators as plumbing
  - make conceptually similar things *look* similar (regardless of
    implementation)
* Example: Routes
** Minimum Amount of Information
   - think about what the *minimum* amount of information needed is
     - everything else is some sort of boilerplate
       - not always bad (ie structure, mnemonic)
       - try to minimize
       - try to make unnecessary information look different from
         necessary information
** Repetition
   - routes are a good example because there are a lot of routes in a
     web app
     - code that repeats a lot should have a structure that helps
       navigate it
     - being terse is extra valuable
   - learn once, use a lot
** Locality
   - try to keep all relevant information in together
     - route URI
     - parameters (and their types)
     - handler
   - keep *unrelated* information separate
     - parsing code
     - code specific to handling the request
* Domain-Specific Languages
  - simple eDSLs are a great application of this idea
  - make code *look like* what it represents
