---
title: Letting Experts Be Experts
author: Tikhon Jelvis
description: Experts aren't just "beginners with more knowledge", they operate in a fundamentally different way. How can we empower rather than hinder them?
image: img/sources-of-power.jpg
---

In my career, I've had the fortune to work with and observe a number of people who were real experts in their fields. Expert programmers, statisticians, designers and leaders. Each expert and each field were different, but there were broad similarities in how all of the experts made decisions. The most effective teams I worked on not only *included* experts but also made room for them to work *as experts*.

But what does this actually entail?

Experts are not “beginners with more knowledge”; their expertise allows them to operate in a categorically different—and more effective!—manner. To work with experts effectively, we need a model of how they actually work. What makes an expert an expert? How do experts make decisions?

![*Sources of Power* by Gary Klein](img/sources-of-power.jpg "The 20th anniversary edition cover of Gary Klein's Sources of Power, with the subtitle How People Make Decisions")

<!--more-->

Gary Klein's [*Sources of Power*][sources-of-power] is my go-to book for understanding how experts make decisions in difficult, high-context situations. In contrast, most of the other research around decision focuses on novices making intentionally artificial decisions in laboratory connections. To understand expertise, we have to look beyond laboratory research and into qualitative research around **naturalistic decision making**.

*Sources of Power* covers a number of different strategies that experts use in nonroutine situations, based on qualitative studies across firefighters, nurses, military commanders, engineers and other kinds of specialists. Across all the fields studied, experts rarely used formal decision-making techniques based on listing or comparing possible alternatives; instead, experts made decisions following a model Klein calls [recognition-primed decision making][rpd] (RPD), which gives us a foundation for understanding how experts actually behave.

::: {.pull-quote .right}
> Experts are not “beginners with more knowledge”; their expertise allows them to operate in a categorically different—and more effective!—manner.
:::

Broadly, the RPD model is that **experts make decisions by finding parallels—consciously or subconsciously—between the current situation and their past experience**. For most decisions, an expert will not carefully list out and consider how to optimize a situation based on “pros and cons”; instead, they will draw analogies to prototype situations from their experience, mentally simulate solutions in the immediate context and **satisfice** rather than optimize (that is, they will find a solution that is *good enough* rather than searching for the *best possible* approach).

Both intuition *and* analysis are key to the model, as explained in the 20th Anniversary Edition forward to *Sources of Power*:

> Inevitably, the success of *Sources of Power* also encouraged caricatures and oversimplifications. One of the most common, and most annoying, is that the RPD model is just about using intuition and gut instinct, as opposed to more systematic decision strategies. Actually, the RPD model posits a two-stage process, starting with intuition, as decision makers recognize how they need to respond, followed by deliberate evaluation as they simulate a possible response to see to see if it will work. A blend of intuition and analysis, not just gut feelings.

One criticism I've seen is that the RPD model is “obvious”. And it *is* obvious, at least in hindsight. If you've seen experts in action or you've developed expertise in some field yourself, the way RPD describes decisions immediately clicks. Klein found this in his own work:

> As we began to present our findings at conferences, we got the reactions, “Of course that's how people make decisions.” Our findings seemed obviously right to everyone, even though they were so different from earlier decision theories. We began to realize that the force of our findings was in their obviousness. Of course the RPD strategy was the strategy used most frequently.

We shouldn't dismiss an idea just because it sounds obvious. The obviousness is misleading. The RPD view of expertise has non-obvious consequences that I've seen both in qualitative research (like the case studies described in *Sources of Power*) as well as my own experience; more importantly, I've seen too many managers and informal leaders act in ways inconsistent with this “obvious” understanding of expertise, building environments actively hostile to expert decision making.

Perhaps the “obvious” idea is not so obvious after all!

</div>
<div class="content">

## Understanding Experts

It's tempting to simplify the RPD model into a truism: experts make decisions based on experience. While this is a true observation, it misses the structured strategies experts employ to use their expertise, and it does not capture the nonlinear way experts differ from beginners. To figure out how organizational structure and culture impact expertise in practice, we need a more nuanced understanding.

::: {.pull-quote .left }
> Experts have sophisticated, intuitive ways to use their experience to make better decisions.
:::

One critical aspect organizationally is that expert decisions are not *legible*.

We like to think that “good” decisions come from comparing alternative possibilities detail-by-detail. If an expert would just write out the possibilities and list out pros and cons, anybody could follow the same reasoning and come to the same decision. Right?

That is simply not how experts make decisions in practice. Here's what Klein found by interviewing firefighting commanders about difficult fires they fought:

> We asked people to tell us about their hardest cases, thinking that these would show the most decision making. But where were the decisions? The commander sees a vertical fire and knows just what to do. But in an instant, that decision is negated because the first has spread. He still knows just what to do in this changed situation. He never seems to decide anything. He is not comparing a favorite option to another option... He is not comparing anything.

The way experts make decisions will not naturally be clear to non-expert observers, and may not even be clear to the experts themselves!

So how *do* experts make decisions?

> Our results turned out to be fairly clear. It was not that the commanders were *refusing* to compare options; rather, they did not *have* to compare options. ...The commanders' secret was that their experience let them see a situation, even a nonroutine one, as an example of a prototype, so they knew the typical course of action right away. Their experience let them identify a reasonable reaction as the first one they considered, so they did not bother thinking of others. They were not being perverse. They were being skillful. We now call this strategy *recognition-primed decision making*.

While not every expert decision is amenable to the RPD model, Klein's research found that experts made recognition-based decisions in 80% of the *nonroutine* cases that they investigated—and the percentage would, presumably, be higher for routine problems.

Fighting a fire is a dangerous, high-tempo situation. It is tempting to say that RPD describes how experts make decisions under extreme time pressure, but surely people are more deliberative and explicit when they have more time and space to make decisions?

It turns out that this is not the case.

> The next possibility we considered was that the RPD model held only during time-pressured decisions. To test this hypothesis [we] studied the way design engineers made decisions about interfaces. ... The decisions could stretch out over days, or even months, rather than seconds and minutes. Even here, the majority of tough decisions were coded as RPD strategies.

Even in technical jobs with longer time-horizons, experts like engineers, programmers and architects still make the majority of their decisions with RPD-style strategies. RPD is a strategy that lets people draw on their experiences and expertise to spend less time and mental energy and reach better decisions than they would with a more deliberative, comparative approach.

Experts across a wide range of fields and time horizons make decisions based on experience rather than using formal comparison-based decision-making processes. Even when experts do reach for comparisons between alternatives, they generally still mix this with intuition, experience and mental simulation. Rather than being an expert technique, formal comparative decision making is used by *beginners* who do not have the experience, confidence and context to make strong decisions up front.

While these observations give us a strong foundation for understanding experts, decisions in the field are far more nuanced and context-specific. *Sources of Power* goes into substantially more detail, exploring not only how experts use *intuition* but also how they:

 1. Use mental simulation
 2. Spot leverage points
 3. Find nonlinear approaches to ill-defined problems
 4. See[^seeing] the world differently from non-experts
 5. Rely on stories, metaphors and analogies
 6. Share information with other experts on the team
 7. Coordinate and communicate *intent*

(These are the titular “sources of power” experts draw on to make decisions and adapt to complex shifting circumstances.)

[^seeing]: Even the concept of “seeing” is nuanced. I ran into a great observation in Kuhn's *Structure of Scientific Revolutions* about how scientists talk and think about “seeing” things like particles, when they can really only detect them after statistically processing measurements from sophisticated instruments.

    > We do not see electrons, but rather their tracks or else bubbles of vapor in a cloud chamber. We do not see electric currents at all, but rather the needle of an ammeter or galvanometer. Yet... I have repeatedly acted as though we did perceive theoretical entities like currents, electrons, and fields, as though we learned to do so from examination of exemplars, and as though in these cases too it would be wrong to replace talk of seeing with talk of criteria and interpretation.

    Experts I've worked with talked—and presumably thought!—in the same terms. People repeatedly talk about "seeing" aspects of a code design or mathematical problem that they perceive *somehow*, even if it isn't something you can see directly with your eyes.

    There is a big gap between seeing a physical object and the kind of “seeing” that experts think about in complex situations!

    In my earlier post [“By Looking”][by-looking] I wrote a quick observation on how organizations often *aren't* willing to trust expert perception. I should have added a similar note about “seeing” as a metaphor there: sometimes the answer to “how will we know?” absolutely should be “by looking!”... as long as we treat “looking” to mean *expert perception in general*.

[by-looking]: /blog/By-Looking

Expert decision making is complicated. *Sources of Power* is an entire book, and still only summarizes a single research program into decision making.

Experts have sophisticated, intuitive ways to use their experience to make better decisions. The way experts reach conclusions will often not be *legible* to outside observers (including managers!) and may not even be entirely clear to the experts themselves. Explaining a decision is a different skill from making the decision!

</div>
<div class="content">

## (Mis)Managing Experts

Given the recognition-primed decision making model, and given that expert decisions are intuitive and illegible, how can we build teams, cultures and organizations that support experts?

My experience has been that, largely, we don't. I've had the fortune of working on some remarkably effective teams, but these were the exception not the rule—I have seen far more processes and expectations that hinder experts than ones that empower.

::: {.pull-quote .left style="width: 35%"}
> Expert programmers see programming *as* planning.
:::

Managers often have *a priori* models for how decisions “should” be made that do not match how experts actually operate.

For example, managers often ask people to break tasks down into small, explicit subtasks—which is fundamentally at odds with how experts see the work:

> [Experts] have mental models of how tasks are supposed to be performed, teams are supposed to coordinate, equipment is supposed to function. ...they know how the subtasks fit together and can adapt the way they perform individual subtasks to blend in with the others. This makes their performance so smooth. They do not even feel that they are performing subtasks because the integration is so strong. If they have to explain what they are doing to novices, they may have to stop and artificially break it down into subtasks. Often they feel uncomfortable teaching the separate steps because they know they are teaching some bad habits. They are teaching the novices to do the task in a choppy way.

Managers also try to structure work into a uniform planning process, with a clear separation between “planning” and “execution”. Klein's research into planning across a number of military and rescue teams found that “planning is not a simple unified activity”; the approach, complexity and detail of plans varied based on context, and plans were often abandoned when circumstances changed. Some problems have circumstances that require separate planning and execution, but in areas that don't, experts naturally combine planning, iteration and execution into a single activity. I've seen this repeatedly working in software. Expert programmers see programming *as* planning[^programming-as-design].

[^programming-as-design]: Programming languages are, perhaps counterintuitively, amazing tools for planning and design. Programming-as-planning is what lets programmers manage an amazing amount of complexity, and the amount of complexity programmers are expected to manage *necessitates* seeing programming as planning.

    [Laurence Tratt][laurence-tratt], a professor of software engineering at KCL, describes this as the “circular specification problem” in [“What Factors Explain the Nature of Software?"][factors]:

    > Our ability to specify what a given piece of software should be is limited by the circular specification problem. We nearly always have to fully build the software in order to know precisely what we want it to be.

    I really need to write a post about how this is both a blessing and a curse of programming as a field, and the role programming languages as tools play in this dynamic.

[laurence-tratt]: https://tratt.net/laurie/

[factors]: https://tratt.net/laurie/blog/2024/what_factors_explain_the_nature_of_software.html

And, as we've seen earlier, formal decision making models based on comparing alternative options do not reflect the actual recognition-driven process experts use for the vast majority of the decision points in their work.

All three of these *a priori* models follow the same pattern: they expect expert decision making to be legible to non-experts, and they reflect how *beginners* approach unfamiliar situations. My theory is that managers naturally tend towards these models not only because they want more direct control over the work but also because they are extrapolating their expectations from how beginners learn. But experts are not just beginners with more knowledge and discipline! Experts have the confidence and expertise to operate in fundamentally different *and more effective* ways than beginners. Expert decision making is an evidence of skill, not a lack of discipline.

If you enforce a process based on one of these flawed models, you can only have one of two outcomes:

  1. You force experts into a beginner decision-making regime. Acting like beginners rather than experts takes more time and energy and results in worse decisions. Experts second-guess their own experience or have their decisions countermanded by non-expert observers.
  2. You push experts to hide how they *actually* make decisions. They make decisions in natural, effective ways, but then they have to force those decisions into an incompatible framework. This wastes effort, drains morale and gives observers a fundamentally misleading picture of how decisions were made.

In both cases, you're contributing to a culture that is actively antithetical to the effective exercise of expertise.

</div>
<div class="content">

## Letting Experts *Be Experts*

So what can we do to actually help rather than hinder experts?

I've seen first hand that organizations—and even subsections *of the same organization*—differ massively in how well they support expert decision-making. Organizational structure and culture affects how experts do their work directly; how hard it is for non-experts to develop and refine expertise; and, perhaps most importantly, how much *leverage* experts get beyond what they could do alone.

### Intent-Oriented Leadership

Experts make decisions about what to do and how to do it based on factors that they can't always even explain themselves. Trying to force experts to make their work legible, or trying to make decisions *for* experts, keeps them from operating *as experts*. But if you don't track and direct expert work directly, how do you *lead* experts? And how can you lead experts in areas where you have not developed real expertise yourself?

This is certainly possible—if *rare*. I've worked with a handful of leaders in the corporate world who did this well, and I recognized the same overall trends in how they led as I've seen in other expert work. Leading experts effectively requires expertise itself! Just like other experts, the ways these leaders behaved and made decisions were often unclear to me as an expert observer, or even not clear *to the leaders themselves*. Leading effectively hinges on tacit knowledge in the same way as performing surgery or landing on an aircraft carrier.

One accessible pattern for leading effectively is to lead *by intent*. For example, Klein talks about “Commander's Intent statements” in the U.S. Army:

> A technique the U.S. Army has tried is to issue Commander's Intent statements along with its mission orders, or operations orders, which give the detail of the plan for the next day. The Commander's Intent statement helps th soldiers read the commander's mind if they run into uncertainty about how to carry out the orders under field conditions.

Unfortunately the actual impact of these statements has been limited in practice. It is difficult to convince higher echelon commanders to give up control, and, even when they are willing to do that, even just communicating intent is difficult. From his research on Commander's Intent statements, Klein extracted a set of seven categories of information that are useful for communicating intent:

> 1. The purpose of the task (the higher-level goals).
> 2. The objective of the task (an image of the desired outcome).
> 3. The sequence of steps in the plan.
> 4. The rationale for the plan.
> 5. The key decisions that may have to be made.
> 6. Antigoals (unwanted outcomes).
> 7. Constraints and other considerations.

In my own work, I've found it useful to develop similar frameworks for what information to track and communicate, adjusted based on the context and nature of the work as well as the experience and personalities of the people I am working with.

I've also found David Marquet's work on intent-based leadership useful; his book ** provides an accessible introduction to the idea illustrated with stories from his time as the captain of the nuclear-powered submarine *USS Santa Fe*[^video].

[^video]: [This video on his work][intent-based-leadership-video] provides a *very* high-level introduction to his ideas.

### Don't Do That

Ultimately, I simply do not have crisp answers on how to build organizations that enable expertise. I do not pretend to be an expert leader *myself*, but I've had the good fortune to work with some expert leaders directly—and even they did not have a clear idea on exactly how they managed to foster effective environments and teams. It's just hard.

My current philosophy is also the title of this post: figure out how to **let experts be experts**. There is no single process that will empower expertise, just like there is no single process that will shut it down completely. But we can inventory the concrete processes and management decisions in an organization and try to understand how they impact expert work. Do the processes provide the space and context experts need to work effectively? Do they push experts into less effective working regimes? If they do, how can we stop that?

In the past, I've made the mistake of conflating *the amount* of process with how much space it leaves for experts. But, in hindsight, this view missed three core aspects:

 - process is not fungible: some process choices will create obstacles for expertise, but other choices can directly support it
 - the causality is reversed: it's not that having low process makes space for expertise, but rather making space for expertise *lets* us function effectively with less process
 - process is, at most, one of several contributing factors: you can have the absolutely best process but still fail to empower experts for illegible reasons

With the benefit of hindsight, I'm trying to make my analysis more specific: what *aspects* of the process support expert-level work? What aspects hinder it, and *how*? What aspects could we change or even *add* to better-support experts?

I do not really have compelling answers to these questions, even just to myself. What would it take to have an effective culture for experts? I know it's possible, I'd know it when I see it, but I have no idea of how to get there.

But simply thinking in these terms is a start.

[rpd]: https://en.wikipedia.org/wiki/Recognition-primed_decision

[sources-of-power]: https://www.goodreads.com/book/show/65229.Sources_of_Power

[intent-based-leadership-video]: https://www.youtube.com/watch?v=pYKH2uSax8U
