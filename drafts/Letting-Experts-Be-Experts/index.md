---
title: Letting Experts Be Experts
author: Tikhon Jelvis
description: Experts aren't just "beginners with more knowledge", they operate in a fundamentally different way. How can we empower rather than hinder them?
image: img/sources-of-power.jpg
---

In my career, I've had the fortune to work with and observe a number of people who were real experts in their fields. Expert programmers, statisticians, designers and leaders. Each expert and each field were different, but there were broad similarities in how all of the experts made decisions. The most effective teams I worked on not only *included* experts but also made room for them to work *as experts*.

But what does this actually entail?

Experts are not “beginners with more knowledge”; their expertise allows them to operate in a categorically different—and more effective!—manner. To work with experts effectively, we need a model of how they actually work. What makes an expert an expert? How do experts make decisions?

![*Sources of Power* by Gary Klein](img/sources-of-power.jpg "The 20th anniversary edition cover of Gary Klein's Sources of Power, with the subtitle How People Make Decisions")

<!--more-->

Gary Klein's [*Sources of Power*][sources-of-power] is my go-to book for understanding how experts make decisions in difficult, high-context situations. In contrast, much of the research around decision making has focused on novices making intentionally artificial decisions in laboratory connections. To understand expertise, we have to look beyond laboratory research and into qualitative research around **naturalistic decision making**.

*Sources of Power* covers a number of different strategies that experts use in nonroutine situations, based on qualitative studies across firefighters, nurses, military commanders, engineers and other kinds of specialists. Across all the fields studied, experts rarely used formal decision-making techniques based on listing or comparing possible alternatives; instead, experts made decisions following a model Klein calls [recognition-primed decision making][rpd] (RPD), which gives us a foundation for understanding how experts actually behave.

::: {.pull-quote .right}
> Experts are not “beginners with more knowledge”; their expertise allows them to operate in a categorically different—and more effective!—manner.
:::

Broadly, the RPD model is that **experts make decisions by finding parallels—consciously or subconsciously—between the current situation and their past experience**. For most decisions, an expert will not carefully list out and consider how to optimize a situation based on “pros and cons”; instead, they will draw analogies to prototype situations from their experience, mentally simulate solutions in the immediate context and **satisfice** rather than optimize (that is, they will find a solution that is *good enough* rather than searching for the *best possible* approach).

Both intuition *and* analysis are key to the model, as explained in the 20th Anniversary Edition forward to *Sources of Power*:

> Inevitably, the success of *Sources of Power* also encouraged caricatures and oversimplifications. One of the most common, and most annoying, is that the RPD model is just about using intuition and gut instinct, as opposed to more systematic decision strategies. Actually, the RPD model posits a two-stage process, starting with intuition, as decision makers recognize how they need to respond, followed by deliberate evaluation as they simulate a possible response to see to see if it will work. A blend of intuition and analysis, not just gut feelings.

One criticism I've seen is that the RPD model is “obvious”. And it *is* obvious, at least in hindsight. If you've seen experts in action or you've developed expertise in some field yourself, the way RPD describes decisions immediately clicks. Klein found this in his own work:

> As we began to present our findings at conferences, we got the reactions, “Of course that's how people make decisions.” Our findings seemed obviously right to everyone, even though they were so different from earlier decision theories. We began to realize that the force of our findings was in their obviousness. Of course the RPD strategy was the strategy used most frequently.

We shouldn't dismiss an idea just because it sounds obvious. The obviousness is misleading. The RPD view of expertise has non-obvious consequences that I've seen both in qualitative research (like the case studies described in *Sources of Power*) as well as my own experience; more importantly, I've seen too many managers and informal leaders act in ways inconsistent with this “obvious” understanding of expertise, building environments actively hostile to expert decision making.

Perhaps the “obvious” idea is not so obvious after all!

</div>
<div class="content">

## Understanding Experts

It's tempting to simplify the RPD model into a truism: experts make decisions based on experience. While this is a true observation, it misses the structured strategies experts employ to use their expertise, and it does not capture the nonlinear way experts differ from beginners. To figure out how organizational structure and culture impact expertise in practice, we need a more nuanced understanding.

::: {.pull-quote .left }
> Experts have sophisticated, intuitive ways to use their experience to make better decisions.
:::

One critical aspect organizationally is that expert decisions are not *legible*.

We like to think that “good” decisions come from comparing alternative possibilities detail-by-detail. If an expert would just write out the possibilities and list out pros and cons, anybody could follow the same reasoning and come to the same decision. Right?

That is simply not how experts make decisions in practice. Here's what Klein found by interviewing firefighting commanders about difficult fires they fought:

> We asked people to tell us about their hardest cases, thinking that these would show the most decision making. But where were the decisions? The commander sees a vertical fire and knows just what to do. But in an instant, that decision is negated because the first has spread. He still knows just what to do in this changed situation. He never seems to decide anything. He is not comparing a favorite option to another option... He is not comparing anything.

The way experts make decisions will not naturally be clear to non-expert observers, and may not even be clear to the experts themselves!

So how *do* experts make decisions?

> Our results turned out to be fairly clear. It was not that the commanders were *refusing* to compare options; rather, they did not *have* to compare options. ...The commanders' secret was that their experience let them see a situation, even a nonroutine one, as an example of a prototype, so they knew the typical course of action right away. Their experience let them identify a reasonable reaction as the first one they considered, so they did not bother thinking of others. They were not being perverse. They were being skillful. We now call this strategy *recognition-primed decision making*.

While not every expert decision is amenable to the RPD model, Klein's research found that experts made recognition-based decisions in 80% of the *nonroutine* cases that they investigated—and the percentage would, presumably, be higher for routine problems.

Fighting a fire is a dangerous, high-tempo situation. It is tempting to say that RPD describes how experts make decisions under extreme time pressure, but surely people are more deliberative and explicit when they have more time and space to make decisions?

It turns out that this is not the case.

> The next possibility we considered was that the RPD model held only during time-pressured decisions. To test this hypothesis [we] studied the way design engineers made decisions about interfaces. ... The decisions could stretch out over days, or even months, rather than seconds and minutes. Even here, the majority of tough decisions were coded as RPD strategies.

Even in technical jobs with longer time-horizons, experts like engineers, programmers and architects still make the majority of their decisions with RPD-style strategies. RPD is a strategy that lets people draw on their experiences and expertise to spend less time and mental energy and reach better decisions than they would with a more deliberative, comparative approach.

Experts across a wide range of fields and time horizons make decisions based on experience rather than using formal comparison-based decision-making processes. Even when experts do reach for comparisons between alternatives, they generally still mix this with intuition, experience and mental simulation. Rather than being an expert technique, formal comparative decision making is used by *beginners* who do not have the experience, confidence and context to make strong decisions up front.

While these observations give us a strong foundation for understanding how experts make decisions, it's always worth remembering that decisions in the field are far more nuanced and context-specific. *Sources of Power* goes into substantially more detail, exploring not only how experts use *intuition* but also how they:

 1. Use mental simulation
 2. Spot leverage points
 3. Find nonlinear approaches to ill-defined problems
 4. See[^seeing] the world differently from non-experts
 5. Rely on stories, metaphors and analogies
 6. Share information with other experts on the team
 7. Coordinate and communicate *intent*
 
(These are the titular “sources of power” experts draw on to make decisions and adapt to complex shifting circumstances.)

[^seeing]: Even the concept of “seeing” is nuanced. I ran into a great observation in Kuhn's *Structure of Scientific Revolutions* about how scientists talk and think about “seeing” things like particles, when they can really only detect them after statistically processing measurements from sophisticated instruments. There is a big gap between seeing a physical object directly and the kind of “seeing” that experts think about in complex situations!

There is a lot of nuance here! *Sources of Power* is a whole book, and, even so, is just a summary of an entire research program into decision making.

Experts have sophisticated, intuitive ways to use their experience to make better decisions. The way experts reach conclusions will often not be *legible* to outside observers (including managers!) and may not even be entirely clear to the experts themselves. Explaining a decision is a different skill from making the decision!

</div>
<div class="content">

## (Mis)Managing Experts

Given the recognition-primed decision making model, and given that expert decisions are intuitive and illegible, how can we build teams, cultures and organizations that support experts?

My experience has been that, largely, we don't. I've had the fortune of working on some remarkably effective teams, but these were the exception not the rule—I have seen far more processes and expectations that hinder experts than ones that empower.

::: {.pull-quote .left style="width: 35%"}
> Expert programmers see programming *as* planning.
:::

Managers often have *a priori* models for how decisions “should” be made that do not match how experts actually operate.

For example, managers often ask people to break tasks down into small, explicit subtasks—which is fundamentally at odds with how experts see the work:

> [Experts] have mental models of how tasks are supposed to be performed, teams are supposed to coordinate, equipment is supposed to function. ...they know how the subtasks fit together and can adapt the way they perform individual subtasks to blend in with the others. This makes their performance so smooth. They do not even feel that they are performing subtasks because the integration is so strong. If they have to explain what they are doing to novices, they may have to stop and artificially break it down into subtasks. Often they feel uncomfortable teaching the separate steps because they know they are teaching some bad habits. They are teaching the novices to do the task in a choppy way.

Managers also try to structure work into a uniform planning process, with a clear separation between “planning” and “execution”. Klein's research into planning across a number of military and rescue teams found that “planning is not a simple unified activity”; the approach, complexity and detail of plans varied based on context, and plans were often abandoned when circumstances changed. Some problems have circumstances that require separate planning and execution, but in areas that don't, experts naturally combine planning, iteration and execution into a single activity. I've seen this repeatedly working in software. Expert programmers see programming *as* planning[^programming-as-design].

[^programming-as-design]: Programming languages are, perhaps counterintuitively, amazing tools for planning and design. Programming-as-planning is what lets programmers manager an amazing amount of complexity, and the amount of complexity programmers are expected to manager *necessitate* seeing programming as planning.

    [Laurence Tratt][laurence-tratt], a professor of software engineering at KCL, describes this as the “circular specification problem” in [“What Factors Explain the Nature of Software?"][factors]:
    
    > Our ability to specify what a given piece of software should be is limited by the circular specification problem. We nearly always have to fully build the software in order to know precisely what we want it to be.
    
    I really need to write a post about how this is both a blessing and a curse of programming as a field, and the role programming languages as tools play in this dynamic.

[laurence-tratt]: https://tratt.net/laurie/

[factors]: https://tratt.net/laurie/blog/2024/what_factors_explain_the_nature_of_software.html

And, as we've seen earlier, formal decision making models based on comparing alternative options do not reflect the actual recognition-driven process experts use for the vast majority of the decision points in their work.

All three of these *a priori* models follow the same pattern: they expect expert decision making to be legible to non-experts, and they reflect how *beginners* approach unfamiliar situations. My theory is that managers naturally tend towards these models not only because they want more direct control over the work but also because they are extrapolating their expectations from how beginners learn. But experts are not just beginners with more knowledge and discipline! Experts have the confidence and expertise to operate in fundamentally different *and more effective* ways than beginners. Expert decision making is an evidence of skill, not a lack of discipline.

If you enforce a process based on one of these flawed models, you can only have one of two outcomes:

  1. You force experts into a beginner decision-making regime. Acting like beginners rather than experts takes more time and energy and results in worse decisions. Experts second-guess their own experience or have their decisions countermanded by non-expert observers.
  2. You push experts to hide how they *actually* make decisions. They make decisions in natural, effective ways, but then they have to force those decisions into an incompatible framework. This wastes effort, drains morale and gives observers a fundamentally misleading picture of how decisions were made.
  
In both cases, you're contributing to a culture that is actively antithetical to the effective exercise of expertise.

</div>
<div class="content">

## Letting Experts *be Experts*

So what can we do to actually help rather than hinder experts?



<!-- TODO: talk about when comparative approaches make sense; see pgs 97–100ish -->

[rpd]: https://en.wikipedia.org/wiki/Recognition-primed_decision

[sources-of-power]: https://www.goodreads.com/book/show/65229.Sources_of_Power
