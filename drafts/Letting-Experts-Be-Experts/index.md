---
title: Letting Experts Be Experts
author: Tikhon Jelvis
---

In my career, I've had the fortune to work with and observe a number of people who were real experts in their fields. Expert programmers, statisticians, designers and leaders. Each expert and each field were different, but there were broad similarities in how all of the experts made decisions. The most effective teams I worked on not only *included* experts but also made room for them to work *as experts*.

But what does this actually entail?

To figure out how to work well *with* experts, we need a good model of what expertise *is*. What makes an expert an expert? How do experts make decisions?

![*Sources of Power* by Gary Klein](img/sources-of-power.jpg "The 20th anniversary edition cover of Gary Klein's Sources of Power, with the subtitle How People Make Decisions")

A solid starting point is the [recognition-primed decision making][rpd] (RPD) model developed by Gary Klein based on a career of qualitative research into expert decision making. I highly recommend Klein's [*Sources of Power*][sources-of-power] which covers the RPD model and the research that led to it.

<!--more-->

</div>
<div class="content">

Klein's work and the RPD model stand out from other research on decision making because it is based on experts making decisions in complex real-world situations rather than novices making decisions in laboratory conditions. 

Broadly, the RPD model is that **experts make decisions by finding parallels—consciously or subconsciously—between the current situation and their past experience**. For most decisions, an expert will not carefully list out and consider how to optimize a situation based on “pros and cons”; instead, they will draw analogies to prototype situations from their experience, mentally simulate solutions in the immediate context and **satisfice** rather than optimize (that is, they will find a solution that is *good enough* rather than searching for the *best possible* approach).

Both intuition *and* analysis are key to the model, as explained in the 20th Anniversary Edition forward to *Sources of Power*:

> Inevitably, the success of *Sources of Power* also encouraged caricatures and oversimplifications. One of the most common, and most annoying, is that the RPD model is just about using intuition and gut instinct, as opposed to more systematic decision strategies. Actually, the RPD model posits a two-stage process, starting with intuition, as decision makers recognize how they need to respond, followed by deliberate evaluation as they simulate a possible response to see to see if it will work. A blend of intuition and analysis, not just gut feelings.

At a high level, the RPD model might seem “obvious”—or, at least, obvious *in hindsight*. But we shouldn't dismiss an idea just because it sounds obvious. The RPD view of expertise has non-obvious nuances and consequences that I've seen both in qualitative research (like the case studies described in *Sources of Power*) as well as my own experience; more importantly, I've seen too many managers and informal leaders act in ways inconsistent with this “obvious” understanding of expertise, building environments actively hostile to expert decision making.

Perhaps the “obvious” idea is not so obvious after all!

</div>
<div class="content">

## Understanding Experts

It's tempting to simplify the RPD model into a truism: experts make decisions based on experience. While this is a true observation, it misses the critical nuances that determine how experts actually make decisions, differentiate experts from non-experts and determine how organizational structure and culture impacts expertise in practice.

One critical aspect is that expert decisions are not *legible*.

We like to think that “good” decisions come from comparing alternative possibilities detail-by-detail. If an expert would just write out the possibilities and list out pros and cons, anybody could follow the same reasoning and come to the same decision. Right?

That is simply not how experts make decisions in practice. Here's what Klein found by interviewing firefighting commanders about difficult fires they fought:

> We asked people to tell us about their hardest cases, thinking that these would show the most decision making. But where were the decisions? The commander sees a vertical fire and knows just what to do. But in an instant, that decision is negated because the first has spread. He still knows just what to do in this changed situation. He never seems to decide anything. He is not comparing a favorite option to another option... He is not comparing anything.

The way experts make decisions will not naturally be clear to non-expert observers, and may not even be clear to the experts themselves!

So how *do* experts make decisions?

> Our results turned out to be fairly clear. It was not that the commanders were *refusing* to compare options; rather, they did not *have* to compare options. ...
>
> The commanders' secret was that their experience let them see a situation, even a nonroutine one, as an example of a prototype, so they knew the typical course of action right away. Their experience let them identify a reasonable reaction as the first one they considered, so they did not bother thinking of others. They were not being perverse. They were being skillful. We now call this strategy *recognition-primed decision making*.

While not every expert decision is amenable to the RPD model, Klein's research found that experts made recognition-based decisions in 80% of the *nonroutine* cases that they investigated—and the percentage would, presumably, be higher for routine problems.

Fighting a fire is a dangerous, high-tempo situation. It is tempting to say that RPD describes how experts make decisions under extreme time pressure, but surely people are more deliberative and explicit when they have more time and space to make decisions?

It turns out that this is not the case.

> The next possibility we considered was that the RPD model held only during time-pressured decisions. To test this hypothesis [we] studied the way design engineers made decisions about interfaces. ... The decisions could stretch out over days, or even months, rather than seconds and minutes. Even here, the majority of tough decisions were coded as RPD strategies.

Even in technical jobs with longer time-horizons, experts like engineers, programmers and architects still make the majority of their decisions with RPD-style strategies. RPD is a strategy that lets people draw on their experiences and expertise to spend less time and mental energy and reach better decisions than they would with a more deliberative, comparative approach.

Experts across a wide range of fields and time horizons make decisions based on experience rather than using formal comparison-based decision-making processes. Even when experts do reach for comparisons between alternatives, they generally still mix this with intuition, experience and mental simulation. Rather than being an expert technique, formal comparative decision making is used by *beginners* who do not have the experience, confidence and context to make strong decisions up front.

While these observations give us a strong foundation for understanding how experts make decisions, it's always worth remembering that decisions in the field are far more nuanced and context-specific. After all, *Sources of Power* is a whole book, and, even so, is just a summary of an entire research program into decision making.

The key conclusion is that experts have sophisticated, intuitive ways to use their experience to make better decisions. The way experts reach conclusions will often not be *legible* to outside observers (including managers!) and may not even be entirely clear to the experts themselves. Explaining a decision is a different skill from making the decision!

</div>
<div class="content">

## (Mis)Managing Experts

Given the recognition-primed decision making model, and given the understanding that expert decisions are intuitive and illegible, how can we build teams, cultures and organizations that support experts?

My experience has been that we largely don't. I have seen far more processes and expectations that hinder experts than ones that empower.

Managers often have *a priori* models for how decisions “should” be made that do not match how experts actually operate. 

For example, it is common to expect people to break tasks down into small, explicit subtasks—which is fundamentally at odds with how experts see the work:

> [Experts] have mental models of how tasks are supposed to be performed, teams are supposed to coordinate, equipment is supposed to function. ...they know how the subtasks fit together and can adapt the way they perform individual subtasks to blend in with the others. This makes their performance so smooth. They do not even feel that they are performing subtasks because the integration is so strong. If they have to explain what they are doing to novices, they may have to stop and artificially break it down into subtasks. Often they feel uncomfortable teaching the separate steps because they know they are teaching some bad habits. They are teaching the novices to do the task in a choppy way.

Similarly, managers try to force a clear separation between “planning” and “execution”, while experts see doing *as* planning and naturally merge the two. This lets experts quickly adjust their approach to adapt to new information and better-handle the problem—but it also makes it harder for managers to understand, track and control the work.

And, as we've seen earlier, formal decision making models based on comparing alternative options do not reflect the actual recognition-driven process experts use for the vast majority of the decision points in their work.

An interesting aspect about these fundamentally poor models of decision making is that—apart from being more legible—they all reflect how *beginners* make decisions when they do not have skills, knowledge and expertise in an area. My theory is that managers naturally tend towards these models not only because they want more direct control over the work but also because they are extrapolating their expectations from how beginners learn. They see experts as “beginners with more knowledge” rather than people whose expertise allows them to operate in a categorically different—and more effective!—manner.

If you enforce a process based on one of these flawed models, you can only have one of two outcomes:

  1. You force experts into a beginner decision-making regime. Acting like beginners rather than experts takes more time and energy and results in worse decisions. Experts second-guess their own experience or have their decisions countermanded by non-expert observers.
  2. You push experts to hide how they *actually* make decisions. They might still make decisions in natural, effective ways, but then they have to force those decisions into an incompatible framework. This wastes effort, drains morale and gives observers a fundamentally misleading picture of how decisions were made.
  
In both cases, you're contributing to a culture that is actively antithetical to the effective exercise of expertise.

</div>
<div class="content">

## Letting Experts *be Experts*

So what can we do to actually help rather than hinder experts?



<!-- TODO: talk about when comparative approaches make sense; see pgs 97–100ish -->

[rpd]: https://en.wikipedia.org/wiki/Recognition-primed_decision

[sources-of-power]: https://www.goodreads.com/book/show/65229.Sources_of_Power
